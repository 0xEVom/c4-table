#!/usr/bin/env python3
import subprocess
from urllib.parse import urlparse
import re
import argparse
from argparse import RawTextHelpFormatter
import json
import concurrent.futures
import itertools
from collections import defaultdict


# %% Argument Handler
def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Generate markdown table of issues from repo link and username on code4rena",
        epilog="Example: c4-table 2024-02-hydradx carrotsmuggler\n"
        "Please make sure gh (github cli) is installed and logged in with access to code4rena backstage",
        formatter_class=RawTextHelpFormatter,
    )
    parser.add_argument(
        "repo_link",
        help="Link to the repo. Accepts one of the following:\n"
        " 1. http link to the findings repo\n"
        " 2. Name of the contest repo\n"
        " 3. Name of the findings repo",
    )
    parser.add_argument(
        "username",
        nargs="?",
        default=None,
        type=str,
        help="case sensitive username to search for",
    )
    parser.add_argument(
        "-v", "--verbose", help="increase output verbosity", action="store_true"
    )
    parser.add_argument(
        "-l",
        "--links-only",
        help="Only lists html links, very fast",
        action="store_true",
    )
    parser.add_argument(
        "-u", "--user-stats", help="List all user stats", action="store_true"
    )
    parser.add_argument(
        "-p",
        "--primary-issues",
        help="List all primary/selected for report issues",
        action="store_true",
    )
    return parser.parse_args()


# Use the function to parse arguments
args = parse_arguments()


# %% Helper functions
# Fetch file list
def fetch_list(owner, repo):
    command = f"gh api '/repos/{owner}/{repo}/git/trees/main?recursive=true' -q '.tree[]|.path'"
    if args.verbose:
        print(command)

    process = subprocess.run(command, shell=True, capture_output=True, text=True)

    if process.returncode != 0:
        print(
            f"Error occurred: Is gh cli installed and logged in with correct user? \n {process.stderr}"
        )
        return None, 0

    if args.verbose:
        print("Success getting file list")

    result = process.stdout.strip().split("\n")

    filtered_elements = [
        element
        for element in result
        if not element.endswith(("Analysis.md", "Q.md", "G.md", "README.md"))
    ]
    issues_count = len(filtered_elements)

    issuenum_by_user = defaultdict(list)

    for element in filtered_elements:
        match = re.match(r"data/(?P<username>.+)-(?P<number>\d+)\.json", element)
        if match:
            temp_username = match.group("username")
            temp_num = int(match.group("number"))
            issuenum_by_user[temp_username].append(temp_num)

    for numbers in issuenum_by_user.values():
        numbers.sort()

    return issuenum_by_user, issues_count


# Fetch issues
def fetch_issues(page_num, responses_per_page, owner, repo):
    command = (
        f'gh api -H "Accept: application/vnd.github+json" '
        f'-H "X-GitHub-Api-Version: 2022-11-28" '
        f'"/repos/{owner}/{repo}/issues?state=all&page={page_num}&per_page={responses_per_page}"'
    )

    process = subprocess.run(command, shell=True, capture_output=True, text=True)

    if process.returncode != 0:
        print(f"Error grabbing issue data. Querying: {command}\n{process.stderr}")
        return []

    if args.verbose:
        print(f"Success getting issue list page: {page_num}")

    # Strip ANSI escape codes
    ansi_escape = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
    cleaned_output = ansi_escape.sub("", process.stdout)

    # Convert string to JSON
    return json.loads(cleaned_output)


# Display
def print_table(
    numbers=[],
    urls=[],
    titles=[],
    status=[],
    dupes=[],
    severities=[],
    username="",
    repo="",
):
    # Calculate maximum lengths
    number = max(
        len(numbers), len(urls), len(titles), len(status), len(dupes), len(severities)
    )
    url_length = len(urls[0]) - len(str(numbers[0])) if urls else 0
    max_num_length = len(str(numbers[-1])) if numbers else 0
    max_dupe_length = len(str(max(dupes))) if dupes else 0
    max_status_length = (
        max(len(s) for s in status if s) if status and any(status) else 0
    )
    max_severity_length = (
        max(len(s) for s in severities if s) if severities and any(severities) else 0
    )
    max_title_length = min(max(len(s) for s in titles), 80) if titles else 0

    def format_column(value, index):
        if index == 0:  # Num
            return f" {str(value).ljust(max_num_length)} "
        elif index == 1:  # URL
            return f" {str(value).ljust(url_length + max_num_length)} "
        elif index == 2:  # Severity
            return f" {str(value).ljust(max_severity_length)} "
        elif index == 3:  # Status
            return f" {str(value).ljust(max_status_length)} "
        elif index == 4:  # Occurences
            return f" {str(value).ljust(max_dupe_length)} "
        elif index == 5:  # Title
            return f" {str(value[:77] + '...' if len(str(value)) > 80 else str(value)).ljust(max_title_length)} "
        return str(value)

    combined_table = [
        "|" + "|".join(format_column(el, i) for i, el in enumerate(elements)) + "|"
        for elements in itertools.zip_longest(
            numbers, urls, severities, status, dupes, titles, fillvalue=""
        )
    ]

    combined_table.insert(0, "| Num | URL | Severity | Status | Occurences | Title |")
    combined_table.insert(1, "| :-: | :-: | :-: | :-: | :-: | :-: |")

    if args.verbose:
        print("\n")
    print("\n".join(combined_table))

    if number > 0:
        print(f"\nFound {number} issues from {username} in {repo} repo\n")
    print(
        "Severity Legend: H - High Risk, M - Medium Risk, QA - Quality Assurance, A - Analysis, G - Gas Optimization"
    )
    print(
        "Status Legend: P - Primary, D{num} - Duplicate, X - Rejected, QA - Quality Assurance, A - Analysis"
    )


# %% Fetch file list and issue numbers
# Parse repo link
http_url = args.repo_link
if http_url[0] == "2":
    owner = "code-423n4"
    if http_url.endswith("findings"):
        repo = http_url
    else:
        repo = http_url + "-findings"
else:
    # Parse the URL
    parsed_url = urlparse(http_url)
    # Extract the owner and repo
    path_parts = parsed_url.path.strip("/").split("/")
    owner = path_parts[0]
    repo = path_parts[1]

issuenum_by_user, issues_count = fetch_list(owner, repo)


# %% Early exits
def handle_links_only(issuenum_by_user, args, owner, repo):
    username = args.username
    if not username:
        print("Username not provided")
        return

    issue_numbers = issuenum_by_user[username]
    url_list = [
        f"https://github.com/{owner}/{repo}/issues/{element}"
        for element in issue_numbers
    ]
    print_table(numbers=issue_numbers, urls=url_list, username=username, repo=repo)


def handle_user_stats(issuenum_by_user, issues_count):
    print(f"{'Username':<20} | {'Number of issues'}")
    print(f"{'-'*20} | {'-'*15}")

    sorted_issuenum_by_user = sorted(
        issuenum_by_user.items(), key=lambda item: len(item[1])
    )

    for username, issue_numbers in sorted_issuenum_by_user:
        print(f"{username:<20} | {len(issue_numbers)} ")

    print(f"Total {issues_count} issues submitted by {len(issuenum_by_user)} users")


# Main early exit logic
if args.links_only:
    handle_links_only(issuenum_by_user, args, owner, repo)
    quit()

if args.user_stats:
    handle_user_stats(issuenum_by_user, issues_count)
    quit()


# %% Fetch issue details
# Get paginated issue details
responses_per_page = 100
pages = (issues_count // responses_per_page) + 1
issues_list = []
with concurrent.futures.ThreadPoolExecutor(max_workers=min(pages + 1, 25)) as executor:
    futures = [
        executor.submit(fetch_issues, page_num, responses_per_page, owner, repo)
        for page_num in range(1, pages + 1)
    ]
    results = [future.result() for future in concurrent.futures.as_completed(futures)]
# Combine results into issues_list
for result in results:
    issues_list.extend(result)
issues_list.sort(key=lambda issue: issue["number"])

# convert issues into an array and find parent issues
modified_length = len(issues_list) + 10
issues_arr = [None] * modified_length
issues_parent = [None] * modified_length
dupes_list = [1] * modified_length
acceptance = [None] * modified_length
severities = [None] * modified_length
primary_issues = []
for issue in issues_list:
    issues_arr[issue["number"]] = issue
    issues_parent[issue["number"]] = issue["number"]

    # First loop: Process labels for acceptance
    for label in issue["labels"]:
        if label["name"] in [
            "insufficient quality report",
            "low quality report",
            "out of scope",
            "unsatisfactory",
            "invalid",
            "nullified",
        ]:
            acceptance[issue["number"]] = "X"
            break
        elif label["name"] == "QA (Quality Assurance)":
            acceptance[issue["number"]] = "QA"
            break
        elif label["name"] == "analysis-advanced":
            acceptance[issue["number"]] = "A"
            break
        elif label["name"] == "G (Gas Optimization)":
            acceptance[issue["number"]] = "G"
            break
        elif label["name"] in [
            "confirmed for report",
            "selected for report",
            "primary issue",
        ]:
            acceptance[issue["number"]] = "P"
        else:
            match = re.match(r"duplicate-(\d+)", label["name"])
            if match:
                issues_parent[issue["number"]] = int(match.group(1))
                dupes_list[int(match.group(1))] += 1
                acceptance[issue["number"]] = f"D{int(match.group(1))}"

    # Second loop: Process all labels for severity
    severities[issue["number"]] = "X"  # Default to X if no other severity is found
    for label in issue["labels"]:
        if label["name"] == "3 (High Risk)":
            severities[issue["number"]] = "H"
        elif label["name"] == "2 (Med Risk)":
            severities[issue["number"]] = "M"
        elif label["name"] == "QA (Quality Assurance)":
            severities[issue["number"]] = "QA"
        elif label["name"] == "analysis-advanced":
            severities[issue["number"]] = "A"
        elif label["name"] == "G (Gas Optimization)":
            severities[issue["number"]] = "G"

    if acceptance[issue["number"]] == "P":
        primary_issues.append(issue["number"])

# %% Primary issues/ Report generation
# Get all issues marked P (selected for report, or primary issues)
if args.primary_issues:
    num_list = [element for element in primary_issues]
    url_list = [issues_arr[element]["html_url"] for element in num_list]
    title_list = [issues_arr[element]["title"] for element in num_list]
    dupes_list_user = [dupes_list[issues_parent[element]] for element in num_list]
    acceptance_list = [acceptance[element] for element in num_list]
    severity_list = [severities[element] for element in num_list]
    print_table(
        numbers=num_list,
        urls=url_list,
        titles=title_list,
        username="Primary Issues",
        dupes=dupes_list_user,
        status=acceptance_list,
        severities=severity_list,
        repo=repo,
    )
    quit()

# %% User specific data
# Get relevant issues
username = args.username
issue_numbers = issuenum_by_user[username]
url_list = [
    element["html_url"] for element in issues_list if element["number"] in issue_numbers
]
title_list = [
    element["title"] for element in issues_list if element["number"] in issue_numbers
]
num_list = [
    element["number"] for element in issues_list if element["number"] in issue_numbers
]
dupes_list_user = [dupes_list[issues_parent[element]] for element in issue_numbers]
acceptance_list = [acceptance[element] for element in issue_numbers]
severity_list = [severities[element] for element in issue_numbers]

# %% Table output
print_table(
    numbers=num_list,
    urls=url_list,
    titles=title_list,
    username=username,
    dupes=dupes_list_user,
    status=acceptance_list,
    severities=severity_list,
    repo=repo,
)
