#!/usr/bin/env python3
import os
import json
import argparse
import itertools
import requests
import concurrent.futures
from urllib.parse import urlparse
from argparse import RawTextHelpFormatter
from collections import defaultdict


# %% Argument Handler
def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Generate markdown table of submissions from Code4rena API for a slug and username",
        epilog="Example: c4-table 2025-06-chainlink-rewards random1106\n"
        "Requires C4AUTH_LOGIN cookie in the environment",
        formatter_class=RawTextHelpFormatter,
    )
    parser.add_argument(
        "contest_ref",
        help="Contest reference. Accepts one of the following:\n"
        " 1. Code4rena contest URL (e.g., https://code4rena.com/audits/2025-06-chainlink-rewards)\n"
        " 2. Contest slug (e.g., 2025-06-chainlink-rewards)",
    )
    parser.add_argument(
        "username",
        nargs="?",
        default=None,
        type=str,
        help="case sensitive username to search for",
    )
    parser.add_argument(
        "-v", "--verbose", help="increase output verbosity", action="store_true"
    )
    parser.add_argument(
        "-u", "--user-stats", help="List all user stats", action="store_true"
    )
    parser.add_argument(
        "-p",
        "--primary",
        help="List all primary/selected submissions",
        action="store_true",
    )
    return parser.parse_args()


# Use the function to parse arguments
args = parse_arguments()


# %% Helper functions
# Fetch file list
def _require_cookie():
    cookie = os.getenv("C4AUTH_LOGIN")
    if not cookie:
        print("C4AUTH_LOGIN environment variable not found. Set it from your browser cookie.")
        exit(1)
    return cookie

def _fetch_submissions(slug):
    cookie = _require_cookie()
    headers = {
        "content-type": "application/json",
        "cookie": f"C4AUTH-LOGIN={cookie}",
    }
    def fetch_page(session, page):
        url = f"https://code4rena.com/api/v1/audits/{slug}/submissions?perPage=100&page={page}"
        resp = session.get(url, headers=headers)
        if resp.status_code != 200:
            try:
                body = resp.json()
            except Exception:
                body = resp.text
            raise RuntimeError(f"HTTP {resp.status_code} page {page}: {body}")
        data = resp.json()
        subs = data.get("data", {}).get("submissions", data.get("data", []))
        if not isinstance(subs, list):
            subs = []
        pagination = data.get("pagination", {})
        return subs, pagination

    submissions = []
    with requests.Session() as session:
        try:
            subs, pagination = fetch_page(session, 1)
        except Exception as e:
            print(f"Error fetching submissions: {e}")
            exit(1)
        submissions.extend(subs)
        last_page = pagination.get("lastPage", 1) or 1
        if last_page > 1:
            pages = list(range(2, last_page + 1))
            with concurrent.futures.ThreadPoolExecutor(max_workers=min(8, len(pages))) as ex:
                futures = {ex.submit(fetch_page, session, p): p for p in pages}
                for fut in concurrent.futures.as_completed(futures):
                    p = futures[fut]
                    try:
                        subs, _ = fut.result()
                        submissions.extend(subs)
                    except Exception as e:
                        print(f"Error fetching page {p}: {e}")
                        exit(1)
    return submissions

def fetch_list(owner, repo_or_slug):
    # Interpret input as slug and build mapping username -> [submission numbers]
    slug = repo_or_slug
    subs = _fetch_submissions(slug)
    issuenum_by_user = defaultdict(list)
    for s in subs:
        # If a submission belongs to a team, index it ONLY under the team handle.
        # Otherwise, index it under the individual user handle.
        handles = []
        team = s.get("team") or {}
        team_handle = team.get("handle")
        if team_handle:
            handles = [team_handle]
        else:
            user_handle = (s.get("user") or {}).get("handle")
            if user_handle:
                handles = [user_handle]
        num = s.get("number")
        if isinstance(num, int):
            for h in handles:
                if num not in issuenum_by_user[h]:
                    issuenum_by_user[h].append(num)
    for numbers in issuenum_by_user.values():
        numbers.sort()
    return issuenum_by_user, len(subs)


# Fetch issues
def fetch_issues(page_num, responses_per_page, owner, repo_or_slug):
    # Deprecated path (GitHub). Intentionally unused.
    return []


# Display
def print_table(
    numbers=[],
    urls=[],
    titles=[],
    status=[],
    dupes=[],
    severities=[],
    username="",
    contest="",
):
    # Calculate maximum lengths
    number = max(
        len(numbers), len(urls), len(titles), len(status), len(dupes), len(severities)
    )
    url_length = len(urls[0]) - len(str(numbers[0])) if urls else 0
    max_num_length = len(str(numbers[-1])) if numbers else 0
    max_dupe_length = len(str(max(dupes))) if dupes else 0
    max_status_length = (
        max(len(s) for s in status if s) if status and any(status) else 0
    )
    max_severity_length = (
        max(len(s) for s in severities if s) if severities and any(severities) else 0
    )
    max_title_length = min(max(len(s) for s in titles), 80) if titles else 0

    def format_column(value, index):
        if index == 0:  # Num
            return f" {str(value).ljust(max_num_length)} "
        elif index == 1:  # URL
            return f" {str(value).ljust(url_length + max_num_length)} "
        elif index == 2:  # Severity
            return f" {str(value).ljust(max_severity_length)} "
        elif index == 3:  # Status
            return f" {str(value).ljust(max_status_length)} "
        elif index == 4:  # Occurences
            return f" {str(value).ljust(max_dupe_length)} "
        elif index == 5:  # Title
            return f" {str(value[:77] + '...' if len(str(value)) > 80 else str(value)).ljust(max_title_length)} "
        return str(value)

    combined_table = [
        "|" + "|".join(format_column(el, i) for i, el in enumerate(elements)) + "|"
        for elements in itertools.zip_longest(
            numbers, urls, severities, status, dupes, titles, fillvalue=""
        )
    ]

    combined_table.insert(0, "| Num | URL | Severity | Status | Occurences | Title |")
    combined_table.insert(1, "| :-: | :-: | :-: | :-: | :-: | :-: |")

    if args.verbose:
        print("\n")
    print("\n".join(combined_table))

    if number > 0:
        print(f"\nFound {number} submissions from {username} in {contest}\n")
    print(
        "Severity Legend: H - High Risk, M - Medium Risk, QA - Quality Assurance, A - Analysis, G - Gas Optimization"
    )
    print(
        "Status Legend: P - Primary, D{num} - Duplicate, X - Rejected, QA - Quality Assurance, A - Analysis"
    )


# %% Fetch list and submission numbers from Code4rena API
# Parse input and derive slug
http_url = args.contest_ref
if http_url.startswith("http"):
    parsed_url = urlparse(http_url)
    parts = parsed_url.path.strip("/").split("/")
    repo_name = parts[1] if len(parts) > 1 else parts[0]
    slug = repo_name[:-9] if repo_name.endswith("-findings") else repo_name
else:
    slug = http_url

owner = "code4rena"

issuenum_by_user, issues_count = fetch_list(owner, slug)


def handle_user_stats(issuenum_by_user, issues_count):
    print(f"{'Username':<20} | {'Number of submissions'}")
    print(f"{'-'*20} | {'-'*15}")

    sorted_issuenum_by_user = sorted(
        issuenum_by_user.items(), key=lambda item: len(item[1])
    )

    for username, issue_numbers in sorted_issuenum_by_user:
        print(f"{username:<20} | {len(issue_numbers)} ")

    print(f"Total {issues_count} submissions submitted by {len(issuenum_by_user)} users")


if args.user_stats:
    handle_user_stats(issuenum_by_user, issues_count)
    quit()


# %% Fetch submission details (single pass via API)
submissions = _fetch_submissions(slug)
submissions.sort(key=lambda s: s.get("number", 0))

# convert issues into an array and find parent issues
issues_arr = {}
issues_parent = {}
dupes_list = defaultdict(lambda: 1)
acceptance = {}
severities = {}
primary_issues = []

# Build a mapping from finding uid to its primary submission number and dup count
primary_by_finding = {}
dups_by_finding = {}
for s in submissions:
    f = s.get("finding") or {}
    fuid = f.get("uid")
    if not isinstance(s.get("number"), int):
        continue
    if fuid:
        if f.get("duplicates") is not None:
            dups_by_finding[fuid] = f.get("duplicates")
        if s.get("isPrimary"):
            primary_by_finding[fuid] = s.get("number")

for s in submissions:
    num = s.get("number")
    if not isinstance(num, int):
        continue
    issues_arr[num] = s
    f = s.get("finding") or {}
    fuid = f.get("uid")
    primary_num = primary_by_finding.get(fuid)
    issues_parent[num] = primary_num if primary_num is not None else num

    # Acceptance/status
    status = None
    if s.get("isPrimary"):
        status = "P"
    else:
        # if invalid
        validity = None
        for ev in (s.get("evaluations") or []):
            if ev.get("type") == "validity":
                validity = ev.get("value")
        if validity == "invalid":
            status = "X"
        elif primary_num is not None:
            status = f"D{primary_num}"
        else:
            status = "D"
    acceptance[num] = status

    # Severity
    sev = s.get("severity") or ""
    sev_code = "H" if sev.lower() == "high" else ("M" if sev.lower() == "medium" else "X")
    severities[num] = sev_code

    if s.get("isPrimary"):
        primary_issues.append(num)
        if fuid in dups_by_finding:
            dupes_list[num] = dups_by_finding[fuid]

# %% Primary issues/ Report generation
# Get all issues marked P (selected for report, or primary issues)
if args.primary:
    num_list = [element for element in primary_issues]
    url_list = [f"https://code4rena.com/contests/{slug}/submissions/{element}" for element in num_list]
    title_list = [issues_arr[element]["title"] for element in num_list]
    dupes_list_user = [dupes_list[issues_parent[element]] for element in num_list]
    acceptance_list = [acceptance[element] for element in num_list]
    severity_list = [severities[element] for element in num_list]
    print_table(
        numbers=num_list,
        urls=url_list,
        titles=title_list,
        username="Primary Submissions",
        dupes=dupes_list_user,
        status=acceptance_list,
        severities=severity_list,
        contest=slug,
    )
    quit()

# %% User specific data
# Get relevant issues
username = args.username
issue_numbers = issuenum_by_user[username]
url_list = [f"https://code4rena.com/contests/{slug}/submissions/{n}" for n in issue_numbers]
title_list = [issues_arr[n]["title"] for n in issue_numbers]
num_list = [n for n in issue_numbers]
dupes_list_user = [dupes_list[issues_parent[n]] for n in issue_numbers]
acceptance_list = [acceptance[n] for n in issue_numbers]
severity_list = [severities[n] for n in issue_numbers]

# %% Table output
print_table(
    numbers=num_list,
    urls=url_list,
    titles=title_list,
    username=username,
    dupes=dupes_list_user,
    status=acceptance_list,
    severities=severity_list,
    contest=slug,
)
