#!/usr/bin/env python3
import subprocess
from urllib.parse import urlparse
import re
import argparse
from argparse import RawTextHelpFormatter
import json
import concurrent.futures
import itertools
from collections import defaultdict

# %% Argument Handler
# Parse arguments
parser = argparse.ArgumentParser(
    description="Generate markdown table of issues from repo link and username on code4rena",
    epilog="Example: c4-table 2024-02-hydradx carrotsmuggler\n"
    "Please make sure gh (github cli) is installed and logged in with access to code4rena backstage",
    formatter_class=RawTextHelpFormatter,
)
parser.add_argument(
    "repo_link",
    help="Link to the repo. Accepts one of the following:\n"
    " 1. http link to the findings repo\n"
    " 2. Name of the contest repo\n"
    " 3. Name of the findings repo",
)
parser.add_argument(
    "username",
    nargs="?",
    default=None,
    type=str,
    help="case sensitive username to search for",
)
parser.add_argument(
    "-v", "--verbose", help="increase output verbosity", action="store_true"
)
parser.add_argument(
    "-l", "--links-only", help="Only lists html links, very fast", action="store_true"
)
parser.add_argument(
    "-u", "--user-stats", help="List all user stats", action="store_true"
)
args = parser.parse_args()


# %% Helper functions
# Fetch file list
def fetch_list(owner, repo):
    # gh command. Ensure gh is installed and logged in
    command = f"gh api '/repos/{owner}/{repo}/git/trees/main?recursive=true' -q '.tree[]|.path'"
    if args.verbose:
        print(command)
    process = subprocess.Popen(
        command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    stdout, stderr = process.communicate()
    if process.returncode != 0:
        print(
            f"Error occurred: Is gh cli installed and logged in with correct user? \n {stderr.decode()}"
        )
    else:
        if args.verbose:
            print(f"Success getting file list")
    result = stdout.decode().strip().split("\n")

    # Remove non subs
    filtered_elements = [
        element
        for element in result
        if not element.endswith(("Analysis.md", "Q.md", "G.md", "README.md"))
    ]
    issues_count = len(filtered_elements)

    issuenum_by_user = defaultdict(list)

    # Iterate over the filtered elements
    for element in filtered_elements:
        # Use a regular expression to match the username and issue number
        match = re.match(r"data/(?P<username>.+)-(?P<number>\d+)\.json", element)
        if match:
            # Extract the username and issue number from the match
            temp_username = match.group("username")
            temp_num = int(match.group("number"))
            # Add the issue number to the list for this username
            issuenum_by_user[temp_username].append(temp_num)

    # Sort the issue numbers for each user
    for numbers in issuenum_by_user.values():
        numbers.sort()
    return issuenum_by_user, issues_count


# Fetch issues
def fetch_issues(page_num, responses_per_page):
    command = f'gh api -H "Accept: application/vnd.github+json" -H "X-GitHub-Api-Version: 2022-11-28" "/repos/{owner}/{repo}/issues?state=all&page={page_num}&per_page={responses_per_page}"'
    process = subprocess.Popen(
        command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    stdout, stderr = process.communicate()
    if process.returncode != 0:
        print(f"Error grabbing issue data. Querying: {command} \n {stderr.decode()}")
    else:
        if args.verbose:
            print(f"Success getting issue list page: {page_num}")
    # Decode stdout from bytes to string
    stdout_str = stdout.decode("utf-8")
    # Strip ANSI escape codes
    ansi_escape = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
    stdout_str = ansi_escape.sub("", stdout_str)
    # Convert string to JSON
    return json.loads(stdout_str)


# Display
def print_table(
    numbers=[], urls=[], titles=[], status=[], dupes=[], username="", repo=""
):
    # Find the largest length
    number = max(len(numbers), len(urls), len(titles), len(status), len(dupes))
    combined_table = [
        "|"
        + "|".join(
            (
                f" {str(el).ljust(6)} "
                if i == 2
                else f" {str(el).ljust(5)} " if i == 3 else f" {str(el)} "
            )
            for i, el in enumerate(elements)
        )
        + "||"
        for elements in itertools.zip_longest(
            numbers, urls, status, dupes, titles, fillvalue=""
        )
    ]
    combined_table.insert(
        0, "| Num | URL | Acceptance | Occurrence | Title | Comments |"
    )
    combined_table.insert(1, "| :-: | :-: | :-: | :-: | :-: | :-: |")
    if args.verbose:
        print("\n")
    print("\n".join(combined_table))
    if number > 0:
        print(f"\nFound {number} issues from {username} in {repo} repo\n")
    print(
        "Legend: P - Primary, D{num} - Duplicate, X - Rejected, QA - Quality Assurance, A - Analysis\n"
    )


# %% Fetch file list and issue numbers
# Parse repo link
http_url = args.repo_link
if http_url[0] == "2":
    owner = "code-423n4"
    if http_url.endswith("findings"):
        repo = http_url
    else:
        repo = http_url + "-findings"
else:
    # Parse the URL
    parsed_url = urlparse(http_url)
    # Extract the owner and repo
    path_parts = parsed_url.path.strip("/").split("/")
    owner = path_parts[0]
    repo = path_parts[1]

issuenum_by_user, issues_count = fetch_list(owner, repo)


# %% Early exits
# Only links (No issue parsing)
if args.links_only:
    username = args.username
    if not username:
        print("Username not provided")
        quit()
    issue_numbers = issuenum_by_user[username]
    url_list = [
        f"https://github.com/{owner}/{repo}/issues/{element}"
        for element in issue_numbers
    ]
    print_table(numbers=issue_numbers, urls=url_list, username=username, repo=repo)
    quit()

if args.user_stats:
    print(f"{'Username':<20} | {'Number of issues'}")
    print(f"{'-'*20} | {'-'*15}")
    # Sort the dictionary by the length of the issue numbers list
    sorted_issuenum_by_user = sorted(
        issuenum_by_user.items(), key=lambda item: len(item[1])
    )
    # Iterate over the sorted dictionary and print the username and number of issues
    for username, issue_numbers in sorted_issuenum_by_user:
        # print(f"User {username} submitted {len(issue_numbers)} issues")
        print(f"{username:<20} | {len(issue_numbers)} ")
    print(f"Total issues submitted: {issues_count}")
    quit()


# %% Fetch issue details
# Get paginated issue details
responses_per_page = 100
pages = (issues_count // responses_per_page) + 1
issues_list = []
with concurrent.futures.ThreadPoolExecutor() as executor:
    futures = [
        executor.submit(fetch_issues, page_num, responses_per_page)
        for page_num in range(1, pages + 1)
    ]
    results = [future.result() for future in concurrent.futures.as_completed(futures)]
# Combine results into issues_list
for result in results:
    issues_list.extend(result)
issues_list.sort(key=lambda issue: issue["number"])

# convert issues into an array and find parent issues
modified_length = len(issues_list) + 10
issues_arr = [None] * modified_length
issues_parent = [None] * modified_length
dupes_list = [1] * modified_length
acceptance = [None] * modified_length
for issue in issues_list:
    issues_arr[issue["number"]] = issue
    issues_parent[issue["number"]] = issue["number"]
    for label in issue["labels"]:
        if (
            label["name"] == "insufficient quality report"
            or label["name"] == "low quality report"
            or label["name"] == "out of scope"
            or label["name"] == "unsatisfactory"
            or label["name"] == "invalid"
        ):
            acceptance[issue["number"]] = "X"
            break
        else:
            if label["name"] == "QA (Quality Assurance)":
                acceptance[issue["number"]] = "QA"
                break
            if label["name"] == "analysis-advanced":
                acceptance[issue["number"]] = "A"
                break
            if (
                label["name"] == "primary issue"
                or label["name"] == "confirmed for report"
                or label["name"] == "selected for report"
            ):
                acceptance[issue["number"]] = "P"
                continue
            match = re.match(r"duplicate-(\d+)", label["name"])
            if match:
                issues_parent[issue["number"]] = int(match.group(1))
                dupes_list[int(match.group(1))] += 1
                acceptance[issue["number"]] = f"D{int(match.group(1))}"
                continue

# %% User specific data
# Get relevant issues
username = args.username
issue_numbers = issuenum_by_user[username]
url_list = [
    element["html_url"] for element in issues_list if element["number"] in issue_numbers
]
title_list = [
    element["title"] for element in issues_list if element["number"] in issue_numbers
]
num_list = [
    element["number"] for element in issues_list if element["number"] in issue_numbers
]
dupes_list = [dupes_list[issues_parent[element]] for element in issue_numbers]
acceptance_list = [acceptance[element] for element in issue_numbers]

# %% Table output
print_table(
    numbers=num_list,
    urls=url_list,
    titles=title_list,
    username=username,
    dupes=dupes_list,
    status=acceptance_list,
    repo=repo,
)
